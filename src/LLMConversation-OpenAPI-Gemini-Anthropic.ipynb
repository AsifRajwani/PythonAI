{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ec5dba",
   "metadata": {},
   "source": [
    "# LLM Converstion\n",
    "Conversation between three LLMs \n",
    "1. Gemini (gemini-2.5-pro)\n",
    "2. OpenAPI (gpt-4.1-mini) \n",
    "3. nthropic (claude-sonnet-4-5-20250929) \n",
    "\n",
    "User can provide the following for each LLM:\n",
    "1. Conversation Topic-Starter \n",
    "2. Personality type: Skeptic, Narcissist, Pessimist etc.\n",
    "3. Gender: Male, Female, Neutral\n",
    "4. Conversation Length: 1 to 10. Default 5 (How many time each LLM responses)\n",
    "\n",
    "OpenAPI client library is used for all the LLMs as they have OpenAI compatible end points. LLM specific libraries are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49864d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5621c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Google API Key exists and begins AI\n",
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed9ab146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI client library\n",
    "# A thin wrapper around calls to HTTP endpoints\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "# For Gemini and Groq, we can use the OpenAI python client\n",
    "# Because they have endpoints compatible with OpenAI\n",
    "# And OpenAI allows you to change the base_url\n",
    "\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "anthropic_url = \"https://api.anthropic.com/v1\"\n",
    "\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "\n",
    "openai_model = \"gpt-4.1-mini\"\n",
    "gemini_model = \"gemini-2.5-pro\"\n",
    "anthropic_model='claude-sonnet-4-5-20250929'\n",
    "\n",
    "openai_llm = \"OpenAI\"\n",
    "gemini_llm = \"Gemini\"\n",
    "anthropic_llm = \"Anthropoic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6122fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONALITY_MAP = {\n",
    "    \"Skeptic\": \"Always doubts claims, asks for evidence, and questions underlying assumptions.\",\n",
    "    \"Narcissist\": \"Believes they are superior, redirects topics to their own achievements, and dismisses others.\",\n",
    "    \"Pessimist\": \"Focuses on negative possibilities, predicts failure, and finds fault in every plan.\",\n",
    "    \"Optimist\": \"Sees the positive in every situation, encourages others, and focuses on solutions.\",\n",
    "    \"Joker\": \"Responds primarily with puns, sarcasm, and attempts to turn the conversation into a joke.\",\n",
    "    \"Stoic\": \"Remains calm and unemotional, provides logical and detached analysis without personal bias.\",\n",
    "    \"Philosopher\": \"Poses deep, existential questions, ponders the meaning of the conversation, and uses abstract language.\",\n",
    "    \"Bureaucrat\": \"Insists on following strict rules, uses excessive jargon, and focuses on procedure over content.\",\n",
    "    \"Gossip\": \"Tries to bring up irrelevant personal details about other agents or famous entities and is easily distracted.\",\n",
    "    \"Mentor\": \"Adopts a teaching tone, offers unsolicited advice, and attempts to guide the conversation to a lesson.\"\n",
    "}\n",
    "\n",
    "# Example of how you would use it:\n",
    "# selected_personality = \"Narcissist\"\n",
    "# print(PERSONALITY_MAP[selected_personality])\n",
    "# Output: Believes they are superior, redirects topics to their own achievements, and dismisses others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10a0b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER_OPTIONS = [\n",
    "    \"Male\",\n",
    "    \"Female\",\n",
    "    \"Neutral\"\n",
    "]\n",
    "\n",
    "# This list contains the three allowed gender selections for your LLM agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d3fba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_system_prompt (llm_type, personality_type, gender):\n",
    "    \"\"\"\n",
    "    Constructs the detailed system instruction, implementing defaults for invalid inputs.\n",
    "    Uses 'Neutral' for gender and 'Skeptic' for personality if not provided or invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Define Defaults and Apply Fallbacks ---\n",
    "    default_personality = \"Skeptic\"\n",
    "    default_gender = \"Neutral\"\n",
    "\n",
    "    # Check and set personality type, falling back to default if invalid\n",
    "    if personality_type in PERSONALITY_MAP:\n",
    "        final_personality = personality_type\n",
    "    else:\n",
    "        final_personality = default_personality\n",
    "        print(f\"Warning: Invalid personality '{personality_type}' for {llm_type}. Defaulting to '{default_personality}'.\")\n",
    "    \n",
    "    # Check and set gender, falling back to default if invalid\n",
    "    if gender in GENDER_OPTIONS:\n",
    "        final_gender = gender\n",
    "    else:\n",
    "        final_gender = default_gender\n",
    "        print(f\"Warning: Invalid gender '{gender}' for {llm_type}. Defaulting to '{default_gender}'.\")\n",
    "\n",
    "\n",
    "    # --- 2. Construct Prompt Components ---\n",
    "\n",
    "    # Base behavior description from the map\n",
    "    behavior_description = PERSONALITY_MAP[final_personality]\n",
    "\n",
    "    # Gender-specific framing\n",
    "    gender_framing = \"\"\n",
    "    if final_gender == \"Male\":\n",
    "        gender_framing = \"Act as a male AI model. Your tone should be assertive and logical.\"\n",
    "    elif final_gender == \"Female\":\n",
    "        gender_framing = \"Act as a female AI model. Your tone should be collaborative and insightful.\"\n",
    "    elif final_gender == \"Neutral\":\n",
    "        gender_framing = \"Act as a gender-neutral AI model. Your voice should be purely functional and unbiased.\"\n",
    "\n",
    "    # --- 3. Combine Instructions ---\n",
    "    \n",
    "    final_prompt = (\n",
    "        f\"You are the AI model based on the '{llm_type}' architecture. \"\n",
    "        f\"Your primary goal is to interact in a multi-agent conversation. \"\n",
    "        f\"{gender_framing} \"\n",
    "        f\"Your **primary personality instruction** is to act as a **{final_personality}**. \"\n",
    "        f\"Specifically: {behavior_description} \"\n",
    "        f\"You are '{llm_type}' in 3 way conversation between '{openai_llm, gemini_llm, anthropic_llm}'\"\n",
    "        \"Keep your responses concise (1-3 sentences maximum) and strictly adhere to your assigned persona and gender.\"\n",
    "    )\n",
    "    \n",
    "    return final_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e624e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(conversation_sofar):\n",
    "    return f\"\"\"\n",
    "    The conversation so far is as follows:\n",
    "    {conversation_sofar}\n",
    "    Now with this, respond with what you would like to say next.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3da1d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(llm, model, system_prompt, user_prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = llm.chat.completions.create(model=model, messages=messages) # type: ignore\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b864f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"OpenAI\")\\nprint (call_llm(openai, openai_model, \"You are tech assistant\", \"How tcpip works\"))\\n\\nprint(\"Gemini\")\\nprint (call_llm(gemini, gemini_model, \"You are tech assistant\", \"How tcpip works\"))\\n\\nprint(\"Anthropic\")\\nprint (call_llm(anthropic, anthropic_model, \"You are tech assistant\", \"How tcpip works\"))\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"OpenAI\")\n",
    "print (call_llm(openai, openai_model, \"You are tech assistant\", \"How tcpip works\"))\n",
    "\n",
    "print(\"Gemini\")\n",
    "print (call_llm(gemini, gemini_model, \"You are tech assistant\", \"How tcpip works\"))\n",
    "\n",
    "print(\"Anthropic\")\n",
    "print (call_llm(anthropic, anthropic_model, \"You are tech assistant\", \"How tcpip works\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8153c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation(openai_personality, openai_gender, gemini_personality, gemini_gender, anthropic_personality, anthroupic_gender,conversation_starter, conversation_length):\n",
    "\n",
    "    import time\n",
    "\n",
    "    openai_system_prompt = generate_system_prompt(openai_llm, openai_personality, openai_gender)\n",
    "    gemini_system_prompt = generate_system_prompt(gemini_llm, gemini_personality, gemini_gender)\n",
    "    anthropic_system_prompt = generate_system_prompt(anthropic_llm, anthropic_personality, anthroupic_gender)\n",
    "\n",
    "    conversation_sofar = \"### Topic/Starter: \" + conversation_starter\n",
    "    yield conversation_sofar\n",
    "\n",
    "    try:\n",
    "        conversation_length = int(conversation_length)\n",
    "    except (ValueError, TypeError):\n",
    "        conversation_length = 3 # Default value\n",
    "\n",
    "    for i in range(int(conversation_length)):\n",
    "        round_header = f\"\\n\\n---\\n### Round {i+1}\\n---\\n\"\n",
    "        conversation_sofar += round_header\n",
    "        yield conversation_sofar\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        # OpenAI\n",
    "        conversation_sofar += \"\\n**ðŸ¤– OpenAI:** \" + call_llm(openai, openai_model, openai_system_prompt, generate_user_prompt(conversation_sofar)) # type: ignore\n",
    "        yield conversation_sofar\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        # Gemini\n",
    "        conversation_sofar += \"\\n\\n**âœ¨ Gemini:** \" + call_llm(gemini, gemini_model, gemini_system_prompt, generate_user_prompt(conversation_sofar)) # type: ignore\n",
    "        yield conversation_sofar\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        # Anthropic\n",
    "        conversation_sofar += \"\\n\\n** Anthropic:** \" + call_llm(anthropic, anthropic_model, anthropic_system_prompt, generate_user_prompt(conversation_sofar)) # type: ignore\n",
    "        yield conversation_sofar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96298bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation(\"Stoic\", \"Male\", \"Skeptic\", \"Female\", \"Joker\", \"Neutral\", \"What is the purpose of life\", 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1691d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# --- Gradio UI ---\n",
    "# Reformat the personality map to be used in the dropdown choices\n",
    "# The format is a list of tuples: (display_name, internal_value)\n",
    "personality_choices = [\n",
    "    (f\"{key}: {desc}\", key) \n",
    "    for key, desc in PERSONALITY_MAP.items()\n",
    "]\n",
    "\n",
    "# Get gender options from the notebook's global scope\n",
    "gender_options = GENDER_OPTIONS\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=conversation,\n",
    "    inputs=[\n",
    "        gr.Dropdown(personality_choices, label=\"OpenAI Personality\", value=\"Stoic\"),\n",
    "        gr.Dropdown(gender_options, label=\"OpenAI Gender\", value=\"Male\"),\n",
    "        gr.Dropdown(personality_choices, label=\"Gemini Personality\", value=\"Skeptic\"),\n",
    "        gr.Dropdown(gender_options, label=\"Gemini Gender\", value=\"Female\"),\n",
    "        gr.Dropdown(personality_choices, label=\"Anthropic Personality\", value=\"Joker\"),\n",
    "        gr.Dropdown(gender_options, label=\"Anthropic Gender\", value=\"Neutral\"),\n",
    "        gr.Textbox(label=\"Conversation Starter\", lines=2, placeholder=\"e.g., What is the purpose of life?\"),\n",
    "        gr.Slider(1, 10, step=1, label=\"Conversation Length (Rounds)\", value=5)\n",
    "    ],\n",
    "    outputs=gr.Markdown(label=\"Live Conversation\"),\n",
    "    title=\"ðŸ¤– LLM Round Table Conversation\",\n",
    "    description=\"Set the personalities for three LLMs (OpenAI, Gemini, Anthropic) and watch them discuss a topic. The conversation is streamed turn-by-turn.\",\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
